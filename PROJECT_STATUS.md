# üöÄ Proyecto ModelAI - Estado Actual

### Sistema Operativo

- **Desarrollo**: Windows 11 + Docker Desktop con WSL2
- **GPU**: NVIDIA RTX 5080 (16GB VRAM, Compute Capability 12.0)
- **CUDA**: 12.8 (en contenedor Docker)
- **PyTorch**: 2.10.0.dev20251108+cu128 (nightly build)

### Arquitectura de Despliegue

- **Contenedorizaci√≥n**: Docker Compose
- **Servicios**:
  - `modelai-redis`: Redis 7 (broker de Celery)
  - `modelai-backend`: FastAPI + SQLite (puerto 8000)
  - `modelai-celery`: Worker de Celery con GPU
- **Imagen Base**: `pytorch/pytorch:2.10.0.dev20251108-cuda12.8-cudnn9-devel`
- **Vol√∫menes Montados**:
  - `./data` ‚Üí `/app/data`
  - `./models` ‚Üí `/app/models`
  - `./output` ‚Üí `/app/output`
  - `./logs` ‚Üí `/app/logs`
  - `./backend` ‚Üí `/app/backend`
  - `./app.db` ‚Üí `/app/app.db`

### Arquitectura del Sistema

```
proyectoModelAI/
‚îú‚îÄ‚îÄ backend/                    # API y l√≥gica de negocio
‚îÇ   ‚îú‚îÄ‚îÄ controllers/            # L√≥gica de controladores
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training_controller.py          ‚úÖ U-Net supervisado (PyTorch)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unsupervised_controller.py      ‚úÖ Autoencoder (PyTorch)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ inference_controller.py         ‚úÖ Inferencia PyTorch
‚îÇ   ‚îú‚îÄ‚îÄ models/                 # Modelos y arquitecturas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ architecture_unet.py            ‚úÖ U-Net PyTorch nativo
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ml_models.py                    ‚úÖ Wrapper PyTorch
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ architecture_autoencoder.py     ‚ÑπÔ∏è  DEPRECATED
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ procesamiento.py                ‚úÖ Procesamiento de im√°genes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ db_models.py                    ‚úÖ Modelos de base de datos
‚îÇ   ‚îú‚îÄ‚îÄ routes/                 # Endpoints de API
‚îÇ   ‚îú‚îÄ‚îÄ tasks/                  # Tareas de Celery
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training_tasks.py               ‚úÖ Entrenamiento supervisado
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unsupervised_tasks.py           ‚úÖ Entrenamiento no supervisado
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ inference_tasks.py              ‚úÖ Inferencia PyTorch
‚îÇ   ‚îú‚îÄ‚îÄ utils/                  # Utilidades
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gpu_config.py                   ‚úÖ Configuraci√≥n GPU PyTorch
‚îÇ   ‚îî‚îÄ‚îÄ scripts/                # Scripts auxiliares
‚îÇ       ‚îî‚îÄ‚îÄ run_unsupervised_training.py    ‚úÖ Runner PyTorch
‚îú‚îÄ‚îÄ frontend_desktop/           # Interfaz de usuario Qt
‚îÇ   ‚îî‚îÄ‚îÄ views/                  # Vistas de la aplicaci√≥n
‚îú‚îÄ‚îÄ models/                     # Modelos entrenados
‚îÇ   ‚îú‚îÄ‚îÄ pytorch_celery_test.pt              (17 MB)
‚îÇ   ‚îî‚îÄ‚îÄ unet_model_*.pt                     (119 MB cada uno)
‚îú‚îÄ‚îÄ start_backend.py            # Inicia FastAPI
‚îú‚îÄ‚îÄ start_celery.py             # Inicia Celery worker
‚îú‚îÄ‚îÄ start_app.py                # Inicia frontend
‚îî‚îÄ‚îÄ generate_zero_masks.py      # Genera m√°scaras de prueba
```

### Componentes Funcionales

#### ‚úÖ Backend (FastAPI en Docker)

- Contenedor: `modelai-backend`
- Puerto: 8000 (mapeado a host)
- Base de datos: SQLite (montado desde host)
- Auto-reload: Activado con Watchdog
- Estado: **Funcionando**

#### ‚úÖ Celery Worker (en Docker con GPU)

- Contenedor: `modelai-celery`
- Broker: Redis (redis:6379 en red Docker)
- GPU: NVIDIA RTX 5080 (passthrough)
- Pool: Solo (single process)
- Tareas registradas: 3
  - `train_model_task` (supervisado)
  - `train_unsupervised_task` (no supervisado)
  - `predict_task` (inferencia)
- Variables de entorno: BATCH_SIZE=4, PATCH_SIZE=64, STRIDE=32
- Estado: **Funcionando**

#### ‚úÖ Redis (en Docker)

- Contenedor: `modelai-redis`
- Versi√≥n: 7-alpine
- Puerto: 6379 (interno)
- Persistencia: Volume `redis_data`
- Estado: **Funcionando**

#### ‚úÖ Entrenamiento No Supervisado (Autoencoder)

- Arquitectura: ConvAutoencoder PyTorch
- Entrada: Im√°genes multiespectrales (.tif)
- Salida: Modelo .pt + threshold
- Uso: Detecci√≥n de anomal√≠as
- Estado: **Probado y funcionando**
- Prueba: 20 im√°genes ‚Üí 14,260 parches en ~80s

#### ‚úÖ Entrenamiento Supervisado (U-Net)

- Arquitectura: U-Net PyTorch nativo
- Entrada: Im√°genes + m√°scaras (.tif)
- Salida: Modelo .pt + history.json
- Uso: Segmentaci√≥n sem√°ntica
- Estado: **Probado y funcionando**
- Prueba: 3 im√°genes ‚Üí 2139 parches, IoU=1.0, Loss=0.0002

#### ‚úÖ Inferencia (Ambos Modelos)

- Arquitectura: U-Net (supervisado) o Autoencoder (no supervisado)
- Entrada: Imagen multiespectral (.tif)
- Salida:
  - U-Net: M√°scara de segmentaci√≥n (.tif)
  - Autoencoder: Mapa de calor de anomal√≠as (.tif)
- Estado: **Probado y funcionando**
- Features:
  - Detecci√≥n autom√°tica de tipo de modelo
  - Carga modelos .pt con y sin metadata
  - Predicci√≥n en batches con GPU
  - Conversi√≥n autom√°tica Windows ‚Üî WSL paths
  - Reconstrucci√≥n de mosaico con promedios
  - C√°lculo de estad√≠sticas de anomal√≠as
  - Soporte para im√°genes grandes (3000√ó4000+)

### Dependencias Principales

```python
# Machine Learning
torch==2.10.0.dev20251108+cu128
torchvision==0.25.0.dev20251109+cu128
torchaudio==2.10.0.dev20251109+cu128

# Backend
fastapi==0.115.8
celery==5.5.3
redis==5.2.1
sqlalchemy==2.0.40

# Procesamiento de im√°genes
rasterio==1.4.3
numpy==2.1.3
scikit-learn==1.6.1
pillow==10.4.0

# Frontend
PyQt5==5.15.11
pyqtgraph==0.13.7
```

### Archivos Eliminados (Limpieza)

**Scripts de prueba temporales:**

- `test_gpu.py` (prueba TensorFlow obsoleta)
- `test_training.py` (prueba obsoleta)
- `test_celery_pytorch.py` (prueba temporal)
- `check_gpu.py` (referencias a TensorFlow)
- `quick_gen_masks.py` (script temporal)
- `test_supervised_training.py` (script temporal)

**C√≥digo deprecated de TensorFlow:**

- `backend/models/architecture_autoencoder.py` (TensorFlow/Keras, ya no se usa)

**Documentaci√≥n obsoleta:**

- `GPU_CONFIG.md` (gu√≠a de TensorFlow)
- `STATUS.md` (estado antiguo con TensorFlow)
- `TRAINING_GUIDE.md` (referencias a .keras)
- `DOCKER_GPU_GUIDE.md` (Docker con TensorFlow)
- `Dockerfile` (imagen tensorflow/tensorflow)
- `docker-compose.yml` (configuraci√≥n TensorFlow)
- `setup_wsl_gpu.sh` (script de setup TensorFlow)

**Otros:**

- Todos los `__pycache__/` (cache de Python)

### GPU Support

- ‚úÖ PyTorch detecta RTX 5080 correctamente
- ‚úÖ CUDA 12.8 support (compatible con driver 13.0)
- ‚úÖ Training en GPU funciona (autoencoder y U-Net)
- ‚úÖ Sin errores de cuInit o CUDA_ERROR_NO_DEVICE

### Actualizaciones Recientes (10 Nov 2025)

‚úÖ **Migraci√≥n a Docker Completada**

- Sistema completamente containerizado con Docker Compose
- Imagen PyTorch nightly con soporte para RTX 5080 (sm_120)
- GPU passthrough funcionando correctamente
- Vol√∫menes montados para persistencia de datos
- Health checks configurados para todos los servicios
- Variables de entorno para configuraci√≥n de memoria

‚úÖ **Detecci√≥n de Errores de Celery**

- Endpoint `/api/v1/training/status` ahora verifica estado real en Celery
- Detecta cuando Celery crashea por OOM (Out of Memory)
- Detecta tareas perdidas (sin celery_task_id despu√©s de 1 minuto)
- Frontend recibe error autom√°ticamente en lugar de quedarse en "running"
- Timeout de 2 horas en tareas de entrenamiento

‚úÖ **GPU Forzada sin Fallback**

- Training requiere GPU obligatoriamente (no fallback a CPU)
- Lanza RuntimeError si CUDA no est√° disponible
- Evita entrenamientos lentos accidentales en CPU

‚úÖ **Optimizaciones de Memoria Implementadas**

- Implementado `LazyImageDataset` para carga diferida de im√°genes
- Reducci√≥n de memoria: ~98% (de ~900MB a ~12-24MB)
- Agregada funci√≥n `get_image_paths()` para obtener rutas sin cargar
- Liberaci√≥n expl√≠cita de memoria despu√©s de cada batch
- Soporta entrenamiento con 190+ im√°genes sin problemas de RAM

‚úÖ **Soporte Dual para Modelos**

- Carga autom√°tica de modelos supervisados (U-Net) y no supervisados (Autoencoder)
- Detecci√≥n autom√°tica de tipo de modelo por estructura
- Inferencia funciona para ambos tipos de modelo
- Conversi√≥n autom√°tica de rutas Windows ‚Üî WSL

‚úÖ **Inferencia de Anomal√≠as Funcionando**

- Modelo autoencoder detecta anomal√≠as por error de reconstrucci√≥n (MSE)
- Soporte para im√°genes multiespectrales grandes (3000√ó4000√ó3)
- Procesamiento en parches con stride configurable
- Salida: mapa de calor de anomal√≠as (.tif)

‚úÖ **Correcciones de Bugs**

- Fixed: Compatibilidad job.id vs job.job_id (schema string-based PKs)
- Fixed: Conversi√≥n de rutas Windows a WSL (/mnt/c/...)
- Fixed: Dimensiones din√°micas del modelo seg√∫n patch_size
- Fixed: Normalizaci√≥n de im√°genes a rango [0,1]
- Fixed: Indexaci√≥n de batches en LazyImageDataset

### Pr√≥ximos Pasos Recomendados

1. **Optimizaciones**

   - Implementar Data Augmentation en entrenamiento
   - Agregar early stopping en training loop
   - Implementar learning rate scheduling

2. **Testing**

   - Crear tests unitarios para controladores
   - Probar inferencia end-to-end con Celery

3. **Frontend**
   - Verificar compatibilidad con nuevos formatos (.pt)
   - Actualizar visualizaciones si es necesario

### C√≥mo Usar

#### Iniciar Servicios con Docker

```bash
# Iniciar todos los servicios (backend, celery, redis)
docker-compose up -d

# Ver logs en tiempo real
docker-compose logs -f

# Ver logs espec√≠ficos
docker-compose logs -f backend
docker-compose logs -f celery

# Detener servicios
docker-compose down
```

#### Frontend (Windows)

```bash
# Activar entorno virtual
.venv\Scripts\activate

# Iniciar frontend
python -m frontend_desktop.main
```

#### Generar M√°scaras de Prueba

```bash
# Windows
python generate_zero_masks.py
```

#### Verificar Estado

```bash
# Estado de contenedores
docker-compose ps

# GPU dentro del contenedor
docker exec modelai-celery nvidia-smi

# Logs de Celery
docker-compose logs celery --tail 100

# Modelos generados
ls -lh models/

# Base de datos
docker exec modelai-backend sqlite3 /app/app.db "SELECT * FROM training_jobs;"
```

### Performance

**Entrenamiento No Supervisado (Autoencoder)**

- Dataset: 20 im√°genes (713x713x5 cada una)
- Parches: 14,260 (64x64)
- GPU: RTX 5080
- Tiempo: ~80 segundos (2 epochs)
- Batch size: 4

**Entrenamiento Supervisado (U-Net)**

- Dataset: 3 im√°genes + m√°scaras
- Parches: 2,139 (128x128)
- GPU: RTX 5080
- Tiempo: ~2 minutos (2 epochs)
- Batch size: 4
- IoU final: 1.0

### Limitaciones Conocidas

- **Rutas Docker**: Backend convierte autom√°ticamente rutas Windows (C:/) a formato Docker (/app/)
- **GPU Memory**: Para im√°genes muy grandes (>6000√ó6000), ajustar BATCH_SIZE en `.env`
- **OOM en Celery**: Linux OOM killer termina proceso sin excepci√≥n Python (exit code 0)
- **Threshold Autoencoder**: Puede necesitar ajuste manual seg√∫n dataset
- **Percentiles**: En im√°genes sin anomal√≠as, percentiles altos pueden ser 0
- **RTX 5080**: Requiere PyTorch nightly (sm_120 no soportado en stable)

### Pruebas Realizadas

‚úÖ **Entrenamiento No Supervisado**

- Dataset: 190 im√°genes .tif
- Memoria: ~12-24MB durante entrenamiento (vs ~900MB antes)
- Resultado: Modelo entrenado exitosamente

‚úÖ **Inferencia de Anomal√≠as**

- Imagen: 3000√ó4000√ó3 p√≠xeles
- Parches: 192 (128√ó128)
- Tiempo: ~4 segundos en RTX 5080
- Resultado: 0.03% p√≠xeles an√≥malos detectados

---

**Fecha de actualizaci√≥n**: 10 de noviembre de 2025
**Versi√≥n PyTorch**: 2.10.0.dev20251108+cu128 (nightly)
**Despliegue**: Docker Compose con GPU passthrough
**Estado**: ‚úÖ Sistema completamente funcional con Docker, PyTorch nightly y detecci√≥n de errores de Celery
