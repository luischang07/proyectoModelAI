# üöÄ Optimizaciones de Memoria para Entrenamiento

## Problema

Cuando se entrena con **muchas im√°genes** (ej. 190+ im√°genes .tif grandes), la RAM se agota porque:

- ‚ùå Se cargaban **todas las im√°genes en memoria** de una vez
- ‚ùå Se convert√≠an a tensores PyTorch antes de entrenar
- ‚ùå No se liberaba memoria entre batches

## Soluci√≥n Implementada

### 1. **Lazy Loading Dataset** üîÑ

**Archivo**: `backend/models/procesamiento.py`

Se cre√≥ `LazyImageDataset` que implementa carga perezosa:

```python
class LazyImageDataset:
    """
    Dataset que carga im√°genes SOLO cuando se necesitan.
    No carga todo en memoria.
    """
    def __getitem__(self, idx):
        # Carga la imagen solo cuando se solicita
        img, _ = load_image(self.image_paths[idx])

        # Redimensionar al patch_size
        img_tensor = torch.from_numpy(img).float().permute(2, 0, 1)
        img_tensor = F.interpolate(
            img_tensor.unsqueeze(0),
            size=(self.patch_size, self.patch_size),
            mode='bilinear'
        ).squeeze(0)

        # Normalizar a [0, 1]
        img_min = img_tensor.min()
        img_max = img_tensor.max()
        img_tensor = (img_tensor - img_min) / (img_max - img_min + 1e-8)

        return img_tensor
```

**Beneficios**:

- ‚úÖ Solo carga las im√°genes del batch actual
- ‚úÖ Libera memoria autom√°ticamente despu√©s de procesar cada batch
- ‚úÖ Soporta datasets ilimitados

### 2. **Liberaci√≥n Expl√≠cita de Memoria** üßπ

**Archivo**: `backend/controllers/unsupervised_controller.py`

Se agreg√≥ limpieza de memoria despu√©s de cada batch:

```python
# Despu√©s de cada batch de entrenamiento
del xb, out, loss
if device.type == 'cuda':
    torch.cuda.empty_cache()
```

**Beneficios**:

- ‚úÖ Libera VRAM de GPU inmediatamente
- ‚úÖ Libera RAM del sistema
- ‚úÖ Evita acumulaci√≥n de tensores no usados

### 3. **DataLoader Optimizado** ‚öôÔ∏è

Se configur√≥ DataLoader con par√°metros √≥ptimos para memoria:

```python
train_loader = DataLoader(
    train_ds,
    batch_size=batch_size,  # Procesar pocas im√°genes a la vez
    shuffle=True,
    num_workers=0,  # Sin multiprocessing (evita duplicar memoria)
    pin_memory=True  # Acelera transferencias a GPU
)
```

**Beneficios**:

- ‚úÖ `num_workers=0`: Evita crear copias de datos en memoria
- ‚úÖ `pin_memory=True`: Acelera CPU‚ÜíGPU sin usar m√°s RAM

### 4. **Train/Val Split sin Cargar Datos** üìä

**Antes**:

```python
# ‚ùå Cargaba todo en memoria primero
x_data = load_images_only(images_folder)  # 190 im√°genes √ó 50MB = 9.5GB RAM!
x_train, x_val = train_test_split(x_data)
```

**Ahora**:

```python
# ‚úÖ Solo obtiene las rutas, no carga im√°genes
image_paths = get_image_paths(images_folder)  # Solo strings!
full_dataset = LazyImageDataset(image_paths)
train_ds, val_ds = random_split(full_dataset)  # Split sin cargar
```

### 5. **C√°lculo de Threshold Optimizado** üéØ

**Antes**:

```python
# ‚ùå Convert√≠a todo el dataset de validaci√≥n a NumPy
recon_arr = np.concatenate(reconstructions)  # Gran array en RAM
```

**Ahora**:

```python
# ‚úÖ Calcula error por batch y libera memoria
for batch in val_loader:
    error = torch.mean((xb - out) ** 2, dim=(1,2,3))
    reconstruction_errors.extend(error.cpu().numpy())
    del xb, out, error  # Liberar inmediatamente
```

---

## Comparaci√≥n de Uso de Memoria

### M√©todo Antiguo (Load All)

```
Ejemplo: 190 im√°genes de 512√ó512√ó3, 8-bit

Memoria en load_images_only():
- NumPy array: 190 √ó 512 √ó 512 √ó 3 √ó 4 bytes = ~450 MB

Memoria despu√©s de train_test_split():
- x_train (80%): ~360 MB
- x_val (20%): ~90 MB

Memoria despu√©s de convertir a tensores:
- x_train_t: ~360 MB
- x_val_t: ~90 MB
- Arrays originales: ~450 MB (si no se liberan)

TOTAL: ~900 MB - 1.2 GB solo para datos
```

### M√©todo Nuevo (Lazy Loading)

```
Memoria inicial:
- image_paths (lista de strings): ~10 KB
- LazyImageDataset (metadata): ~1 KB

Memoria durante entrenamiento (batch_size=8):
- batch actual en RAM: 8 √ó 512 √ó 512 √ó 3 √ó 4 = ~12 MB
- batch en GPU: ~12 MB
- Despu√©s de liberar: ~0 MB

TOTAL: ~12-24 MB durante entrenamiento
```

**üéØ Reducci√≥n de memoria: ~98%**

---

## Configuraci√≥n Recomendada

### Para GPUs con poca VRAM (< 8GB):

```python
batch_size = 4  # Menos im√°genes por batch
```

### Para GPUs con VRAM moderada (8-12GB):

```python
batch_size = 8  # Balance entre velocidad y memoria
```

### Para GPUs con mucha VRAM (> 12GB):

```python
batch_size = 16  # M√°xima velocidad
```

---

## Funciones A√±adidas

### `get_image_paths(images_folder) ‚Üí List[str]`

Obtiene rutas de todas las im√°genes .tif sin cargarlas.

**Uso**:

```python
paths = procesamiento.get_image_paths("C:/imagenes/")
print(f"Encontradas {len(paths)} im√°genes")
```

### `LazyImageDataset`

Dataset de PyTorch con carga diferida.

**Uso**:

```python
dataset = procesamiento.LazyImageDataset(
    image_paths=paths,
    patch_size=128,
    cancel_check_fn=check_cancelled
)

loader = DataLoader(dataset, batch_size=8, shuffle=True)
for batch in loader:
    # Batch se carga aqu√≠, no antes
    train(batch)
```

---

## Verificaci√≥n

Para verificar que funciona correctamente:

1. **Antes de entrenar**:

   ```python
   import psutil
   print(f"RAM antes: {psutil.virtual_memory().percent}%")
   ```

2. **Durante entrenamiento**: Monitorear con Task Manager (Windows) o `nvidia-smi` (GPU)

3. **Despu√©s de liberar**:
   ```python
   torch.cuda.empty_cache()  # Liberar GPU
   print(f"RAM despu√©s: {psutil.virtual_memory().percent}%")
   ```

---

## Changelog

### 2025-11-10

- ‚úÖ Agregado resize autom√°tico a `patch_size` en `LazyImageDataset`
- ‚úÖ Implementada normalizaci√≥n min-max a [0,1] en `__getitem__`
- ‚úÖ Fixed: Conversi√≥n de rutas Windows a WSL en `load_image()` y `load_mask()`
- ‚úÖ Fixed: Modelo din√°mico seg√∫n patch_size en `ConvAutoencoder`
- ‚úÖ Probado: Entrenamiento exitoso con 190 im√°genes
- ‚úÖ Probado: Inferencia exitosa en imagen 3000√ó4000√ó3

### 2025-11-09

- ‚úÖ Implementado `LazyImageDataset` para lazy loading
- ‚úÖ Agregado `get_image_paths()` para obtener rutas sin cargar
- ‚úÖ Actualizado `execute_unsupervised_training()` para usar lazy loading
- ‚úÖ Agregada liberaci√≥n expl√≠cita de memoria despu√©s de cada batch
- ‚úÖ Optimizado c√°lculo de threshold para no acumular tensores
- ‚úÖ Configurado DataLoader con `num_workers=0` y `pin_memory=True`

---

## Notas T√©cnicas

- **PyTorch DataLoader**: Por defecto no libera memoria agresivamente. Es necesario usar `del` + `torch.cuda.empty_cache()`
- **num_workers=0**: En Windows, multiprocessing puede causar duplicaci√≥n de memoria. Se desactiva para evitar esto
- **pin_memory**: Mejora velocidad de transferencia CPU‚ÜíGPU sin incrementar uso de RAM significativamente
- **random_split**: Divide dataset sin duplicar datos, solo crea √≠ndices

---

## Pr√≥ximas Mejoras Posibles

1. **Cach√© de im√°genes frecuentes**: Guardar en RAM las im√°genes m√°s usadas
2. **Compresi√≥n on-the-fly**: Comprimir im√°genes en RAM y descomprimir solo al usar
3. **Memory mapping**: Usar `np.memmap()` para archivos grandes
4. **Gradient accumulation**: Para batches m√°s grandes sin m√°s memoria
