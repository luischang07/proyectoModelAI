# ğŸŒ¾ U-Net Anomaly Detection System - Arquitectura MVC

Sistema completo de detecciÃ³n de anomalÃ­as en imÃ¡genes multiespectrales con **entrenamiento supervisado Y no supervisado** usando arquitectura MVC + APIs REST.

## âœ¨ CaracterÃ­sticas Principales

- ğŸ¯ **Entrenamiento Supervisado**: U-Net con mÃ¡scaras etiquetadas (alta precisiÃ³n)
- ğŸ§  **Entrenamiento No Supervisado**: Autoencoder sin mÃ¡scaras (no requiere etiquetado)
- ğŸš€ **Backend REST API**: FastAPI con procesamiento asÃ­ncrono (Celery)
- ğŸ–¥ï¸ **Frontend Desktop**: Interfaz grÃ¡fica PyQt5 intuitiva
- ğŸ“Š **Monitoreo en tiempo real**: Progreso y mÃ©tricas en vivo
- ğŸ³ **Docker Ready**: Redis containerizado para producciÃ³n

## ğŸ—ï¸ Arquitectura

```
â”œâ”€â”€ backend/                    # API REST (FastAPI)
â”‚   â”œâ”€â”€ models/                 # Capa MODEL (Datos & ML)
â”‚   â”‚   â”œâ”€â”€ db_models.py        # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ ml_models.py        # U-Net wrapper
â”‚   â”‚   â”œâ”€â”€ procesamiento.py    # Procesamiento de imÃ¡genes
â”‚   â”‚   â”œâ”€â”€ architecture_unet.py        # U-Net para supervisado
â”‚   â”‚   â””â”€â”€ architecture_autoencoder.py # Autoencoder para no supervisado
â”‚   â”œâ”€â”€ controllers/            # Capa CONTROLLER (LÃ³gica)
â”‚   â”‚   â”œâ”€â”€ training_controller.py      # Entrenamiento supervisado
â”‚   â”‚   â”œâ”€â”€ unsupervised_controller.py  # Entrenamiento no supervisado
â”‚   â”‚   â””â”€â”€ inference_controller.py
â”‚   â”œâ”€â”€ routes/                 # Endpoints API
â”‚   â”‚   â”œâ”€â”€ training.py         # POST /training/start (supervisado)
â”‚   â”‚   â”œâ”€â”€ unsupervised.py     # POST /unsupervised/train (no supervisado)
â”‚   â”‚   â”œâ”€â”€ inference.py
â”‚   â”‚   â””â”€â”€ models.py
â”‚   â”œâ”€â”€ tasks/                  # Celery tasks (async)
â”‚   â”‚   â”œâ”€â”€ training_tasks.py
â”‚   â”‚   â”œâ”€â”€ unsupervised_tasks.py
â”‚   â”‚   â””â”€â”€ inference_tasks.py
â”‚   â””â”€â”€ main.py                 # FastAPI app
â”‚
â”œâ”€â”€ frontend_desktop/           # Capa VIEW (PyQt5)
â”‚   â”œâ”€â”€ views/
â”‚   â”‚   â”œâ”€â”€ main_window.py
â”‚   â”‚   â”œâ”€â”€ training_view.py
â”‚   â”‚   â”œâ”€â”€ inference_view.py
â”‚   â”‚   â””â”€â”€ results_view.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ api_client.py       # Cliente HTTP
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ data/                       # Datasets
â”œâ”€â”€ models/                     # Modelos entrenados
â”œâ”€â”€ output/                     # Resultados
â””â”€â”€ logs/                       # Logs
```

## ğŸ“‹ Requisitos Previos

### 1. Python 3.11+

### 2. Redis (para Celery)

**Windows - OpciÃ³n Recomendada: Docker Compose**

```powershell
# AsegÃºrate de tener Docker Desktop instalado
docker-compose up -d

# Verificar
docker ps
```

**Alternativas:**

- **WSL2 + Ubuntu**: `wsl --install` â†’ `sudo apt install redis-server`
- **Memurai**: https://www.memurai.com/ (Redis nativo para Windows)

## ğŸš€ InstalaciÃ³n

### 1. Clonar y crear entorno

```powershell
cd proyectoModelAI
python -m venv .venv
& ".\.venv\Scripts\Activate.ps1"
```

### 2. Instalar dependencias

```powershell
python -m pip install -r requirements.txt
```

## â–¶ï¸ EjecuciÃ³n

### ğŸ³ OpciÃ³n A: Docker (Recomendado para ProducciÃ³n)

```bash
# Iniciar todos los servicios con un solo comando
docker-compose up -d

# Ver logs
docker-compose logs -f

# Detener servicios
docker-compose down
```

ğŸ“š **[GuÃ­a completa de Docker: DOCKER_GUIDE.md](DOCKER_GUIDE.md)**

### ğŸ’» OpciÃ³n B: EjecuciÃ³n Local (Desarrollo)

#### Terminal 1: Redis

```powershell
# Si usas Docker solo para Redis (Recomendado)
docker-compose up -d redis

# Si usas WSL
wsl -d Ubuntu
redis-server

# Si usas Memurai, se ejecuta como servicio automÃ¡tico
```

### Terminal 2: Backend API

```powershell
python start_backend.py

# O manualmente:
# python -m uvicorn backend.main:app --reload
```

Accede a la documentaciÃ³n interactiva:

- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

### Terminal 3: Celery Worker

```powershell
python start_celery.py

# O manualmente:
# celery -A backend.tasks.celery_app worker --loglevel=info --pool=solo
```

### Terminal 4: Frontend Desktop

```powershell
python start_app.py

# O manualmente:
# python frontend_desktop/main.py
```

## ğŸ“± Uso de la AplicaciÃ³n

### ğŸ¯ Seleccionar Tipo de Entrenamiento

La aplicaciÃ³n ahora soporta **DOS modos de entrenamiento**:

#### 1ï¸âƒ£ **Supervisado (con mÃ¡scaras)**

- âœ… Requiere: ImÃ¡genes + MÃ¡scaras etiquetadas
- âœ… Modelo: U-Net
- âœ… Ideal para: Alta precisiÃ³n en anomalÃ­as conocidas
- âœ… Usa cuando: Tienes datos etiquetados manualmente

#### 2ï¸âƒ£ **No Supervisado (sin mÃ¡scaras)**

- âœ… Requiere: Solo imÃ¡genes (sin mÃ¡scaras)
- âœ… Modelo: Autoencoder
- âœ… Ideal para: Detectar anomalÃ­as desconocidas
- âœ… Usa cuando: NO tienes mÃ¡scaras etiquetadas

ğŸ“š **[Lee la guÃ­a completa: TRAINING_GUIDE.md](TRAINING_GUIDE.md)**

---

### 1. Entrenar Modelo (SUPERVISADO)

1. Abre la pestaÃ±a **"ğŸ“š Entrenar Modelo"**
2. Selecciona **"Supervisado (con mÃ¡scaras)"** en el dropdown
3. Selecciona carpeta de **imÃ¡genes** (.tif)
4. Selecciona carpeta de **mÃ¡scaras** (.tif) â† **Requerido**
5. Configura parÃ¡metros:
   - Patch Size: 128 (recomendado, ajustado para memoria)
   - Stride: 64 (50% overlap)
   - Batch Size: 4-8 (ajustar segÃºn GPU)
   - Epochs: 25-50
   - Backbone: resnet34, efficientnetb0, etc.
6. Click en **"ğŸš€ INICIAR ENTRENAMIENTO"**
7. Monitorea progreso: Loss, IoU Score en tiempo real

### 2. Entrenar Modelo (NO SUPERVISADO)

1. Abre la pestaÃ±a **"ğŸ“š Entrenar Modelo"**
2. Selecciona **"No Supervisado (sin mÃ¡scaras - Autoencoder)"** en el dropdown
3. Selecciona carpeta de **imÃ¡genes** (.tif) - Solo imÃ¡genes normales/sanas
4. Campo de mÃ¡scaras se deshabilita automÃ¡ticamente â† **No requerido**
5. Configura parÃ¡metros:
   - Batch Size: 16 (mÃ¡s alto para autoencoder)
   - Epochs: 50-100 (necesita mÃ¡s Ã©pocas)
   - Latent Dim: 128 (tamaÃ±o del espacio latente)
6. Click en **"ğŸš€ INICIAR ENTRENAMIENTO"**
7. Monitorea progreso: Loss, MAE en tiempo real

âš ï¸ **Importante para No Supervisado**:

- Entrena **SOLO con imÃ¡genes NORMALES/SANAS**
- El modelo aprende quÃ© es "normal"
- En inferencia detectarÃ¡ anomalÃ­as por alto error de reconstrucciÃ³n

### 3. Inferencia

1. Abre la pestaÃ±a **"ğŸ” Inferencia"**
2. Selecciona imagen de prueba
3. Elige modelo entrenado (supervisado o no supervisado)
4. Ajusta umbral (0.5 por defecto)
5. Click en **"ğŸ¯ PREDECIR ANOMALÃAS"**
6. Revisa resultados en `output/`

### 4. Ver Resultados

1. Abre la pestaÃ±a **"ğŸ“Š Resultados"**
2. Ve lista de modelos entrenados
3. Click en **"ğŸ”„ Actualizar"** para refrescar

## ğŸ”Œ API Endpoints

### Training (Supervisado)

```http
POST   /api/v1/training/start
GET    /api/v1/training/status/{job_id}
DELETE /api/v1/training/cancel/{job_id}
```

### Training (No Supervisado) âœ¨ **NUEVO**

```http
POST   /api/v1/unsupervised/train
```

**Request Body Example:**

```json
{
  "model_name": "autoencoder_cultivo1",
  "images_folder": "data/images",
  "epochs": 50,
  "batch_size": 16,
  "latent_dim": 128,
  "validation_split": 0.2
}
```

### Inference

```http
POST   /api/v1/inference/predict
GET    /api/v1/inference/status/{job_id}
```

### Models

```http
GET    /api/v1/models/
GET    /api/v1/models/{model_id}
DELETE /api/v1/models/{model_id}
```

## ğŸ› Troubleshooting

### Backend no se conecta

```powershell
# Verificar que Redis estÃ© corriendo
redis-cli ping
# Debe responder: PONG

# Verificar que FastAPI estÃ© corriendo
curl http://localhost:8000/health
```

### Celery no procesa tareas

```powershell
# Verificar logs de Celery
# Debe decir: "ready" o "celery@... ready"

# Reiniciar Celery
# Ctrl+C en la terminal de Celery
python start_celery.py
```

### PyQt5 no se muestra correctamente

```powershell
# Reinstalar PyQt5
pip uninstall PyQt5
pip install PyQt5==5.15.9
```

## ğŸ“Š Estructura de Datos

### ğŸ“ Carpetas Requeridas

#### Para Entrenamiento **SUPERVISADO** (con mÃ¡scaras)

```
data/
â”œâ”€â”€ images/          # ImÃ¡genes originales multiespectrales
â”‚   â”œâ”€â”€ vuelo1.tif
â”‚   â”œâ”€â”€ vuelo2.tif
â”‚   â””â”€â”€ ...
â””â”€â”€ masks/           # MÃ¡scaras binarias de segmentaciÃ³n
    â”œâ”€â”€ vuelo1.tif   # Mismo nombre que la imagen correspondiente
    â”œâ”€â”€ vuelo2.tif
    â””â”€â”€ ...
```

#### Para Entrenamiento **NO SUPERVISADO** (sin mÃ¡scaras) âœ¨ **NUEVO**

```
data/
â””â”€â”€ images/          # Solo imÃ¡genes NORMALES/SANAS
    â”œâ”€â”€ sano_001.tif
    â”œâ”€â”€ sano_002.tif
    â”œâ”€â”€ sano_003.tif
    â””â”€â”€ ...
```

âš ï¸ **Importante**: Para no supervisado, usa **SOLO imÃ¡genes sin anomalÃ­as** (cultivo sano).

---

### ğŸ“¸ Formato de ImÃ¡genes Originales

- **Formato**: `.tif` o `.tiff` (GeoTIFF)
- **Tipo**: ImÃ¡genes multiespectrales capturadas con dron UAV
- **Canales**: RGB, NIR (Infrarrojo Cercano), RedEdge, etc.
  - Depende de tu cÃ¡mara multiespectral (e.g., Parrot Sequoia, MicaSense)
- **UbicaciÃ³n**: `data/images/`

### ğŸ¯ Formato de MÃ¡scaras de SegmentaciÃ³n (Solo para Supervisado)

- **Formato**: `.tif` o `.tiff` (GeoTIFF)
- **Tipo**: MÃ¡scaras binarias de anotaciÃ³n
- **Valores**:
  - `0` (negro) = Ãrea sana/normal del cultivo
  - `1` (blanco) = Ãrea con anomalÃ­a/problema detectado
- **Requisitos**:
  - âš ï¸ **Mismo nombre** que la imagen correspondiente (ej: `vuelo1.tif` â†’ `vuelo1.tif`)
  - âš ï¸ **Mismas dimensiones** (ancho Ã— alto) que la imagen
  - âš ï¸ Se recomienda conservar la georeferenciaciÃ³n (opcional)
- **UbicaciÃ³n**: `data/masks/`
- **ğŸš« NO requerido** para entrenamiento no supervisado

### ğŸ› ï¸ Generar MÃ¡scaras en Cero (Cultivo Sano)

Si solo tienes imÃ¡genes de cultivo sano sin anomalÃ­as, usa el script:

```powershell
python generate_zero_masks.py
```

Esto crearÃ¡ mÃ¡scaras completamente negras (valor 0 = todo sano) automÃ¡ticamente.

**Alternativa**: Usa el modo **No Supervisado** que no requiere mÃ¡scaras en absoluto! ğŸ‰

### ğŸ“ Herramientas para Crear MÃ¡scaras (Solo Supervisado)

- **QGIS** (gratuito) - Para imÃ¡genes georreferenciadas
- **LabelMe** - Para anotaciÃ³n manual
- **GIMP/Photoshop** - EdiciÃ³n de imÃ¡genes
- **Python + OpenCV** - AutomatizaciÃ³n programÃ¡tica

## ï¿½ ComparaciÃ³n: Supervisado vs No Supervisado

| CaracterÃ­stica               | Supervisado         | No Supervisado      |
| ---------------------------- | ------------------- | ------------------- |
| **Requiere mÃ¡scaras**        | âœ… SÃ­               | âŒ No               |
| **Modelo**                   | U-Net               | Autoencoder         |
| **PrecisiÃ³n**                | â­â­â­â­â­ Alta     | â­â­â­ Media        |
| **Tiempo preparaciÃ³n**       | ğŸ• Alto (etiquetar) | âš¡ RÃ¡pido           |
| **Detecta anomalÃ­as nuevas** | âŒ Solo conocidas   | âœ… Cualquiera       |
| **Cantidad de datos**        | Media (100-1000)    | Alta (1000+)        |
| **Uso tÃ­pico**               | Alta precisiÃ³n      | ExploraciÃ³n inicial |

ğŸ“š **[GuÃ­a completa: TRAINING_GUIDE.md](TRAINING_GUIDE.md)**

## PrÃ³ximos Pasos

- [x] Entrenamiento no supervisado (Autoencoder)
- [x] Interfaz para elegir tipo de entrenamiento
- [ ] Inferencia con Autoencoder (detectar anomalÃ­as)
- [ ] AÃ±adir autenticaciÃ³n (JWT)
- [ ] Implementar frontend web (React)
- [ ] Agregar data augmentation
- [ ] Soporte para modelos pre-entrenados
- [ ] Dashboard de mÃ©tricas (Grafana)
- [ ] Docker deployment completo

## ğŸ“š DocumentaciÃ³n Adicional

- **[DOCKER_GUIDE.md](DOCKER_GUIDE.md)** - ğŸ³ GuÃ­a completa de despliegue con Docker
- **[TRAINING_GUIDE.md](TRAINING_GUIDE.md)** - GuÃ­a completa de entrenamiento supervisado vs no supervisado
- **[OPTIMIZACIONES_MEMORIA.md](OPTIMIZACIONES_MEMORIA.md)** - Optimizaciones de memoria para entrenamiento
- **[PROJECT_STATUS.md](PROJECT_STATUS.md)** - Estado actual del proyecto y arquitectura
- **[README_MVC.md](README_MVC.md)** - DocumentaciÃ³n tÃ©cnica de arquitectura MVC

## ğŸ“„ Licencia

MIT License

## ğŸ‘¥ Autores

Sistema desarrollado para detecciÃ³n de anomalÃ­as en cultivos con imÃ¡genes UAV multiespectrales.
