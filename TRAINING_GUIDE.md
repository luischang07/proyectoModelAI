# ğŸ§  GuÃ­a de Entrenamiento: Supervisado vs No Supervisado

## ğŸ“– Resumen

Este proyecto ahora soporta **DOS tipos de entrenamiento**:

### 1ï¸âƒ£ **Supervisado** (con mÃ¡scaras etiquetadas)

- **Modelo**: U-Net con encoder preentrenado
- **Requiere**: ImÃ¡genes + MÃ¡scaras binarias etiquetadas
- **Uso**: Cuando tienes datos etiquetados (mÃ¡scaras dibujadas)
- **Resultado**: SegmentaciÃ³n precisa de anomalÃ­as conocidas

### 2ï¸âƒ£ **No Supervisado** (sin mÃ¡scaras) âœ¨ **NUEVO**

- **Modelo**: Autoencoder convolucional
- **Requiere**: Solo imÃ¡genes (sin mÃ¡scaras)
- **Uso**: Cuando NO tienes datos etiquetados
- **Resultado**: Detecta anomalÃ­as por error de reconstrucciÃ³n

---

## ğŸ¯ Â¿CuÃ¡ndo usar cada uno?

### Usa **SUPERVISADO** si:

- âœ… Tienes mÃ¡scaras etiquetadas (anomalÃ­as marcadas manualmente)
- âœ… Sabes exactamente quÃ© buscar
- âœ… Quieres alta precisiÃ³n en segmentaciÃ³n
- âœ… Tienes tiempo para etiquetar datos

**Ejemplo**: Detectar Ã¡reas con plagas especÃ­ficas que ya conoces

### Usa **NO SUPERVISADO** si:

- âœ… NO tienes mÃ¡scaras etiquetadas
- âœ… No tienes tiempo/recursos para etiquetar
- âœ… Quieres detectar anomalÃ­as desconocidas
- âœ… Solo tienes imÃ¡genes "normales" disponibles

**Ejemplo**: Detectar cualquier anomalÃ­a nueva/desconocida en cultivos

---

## ğŸ”¬ CÃ³mo funciona cada modelo

### Supervisado (U-Net)

```
Entrada: Imagen (RGB/multiespectral)
Salida: MÃ¡scara de segmentaciÃ³n (0=sano, 1=anomalÃ­a)

Entrenamiento:
  - Aprende de pares (imagen, mÃ¡scara_etiquetada)
  - Minimiza diferencia entre predicciÃ³n y mÃ¡scara real
  - Requiere Ground Truth
```

### No Supervisado (Autoencoder)

```
Entrada: Imagen (RGB/multiespectral)
Salida: Imagen reconstruida + Error de reconstrucciÃ³n

Entrenamiento:
  - Aprende a reconstruir imÃ¡genes NORMALES
  - Solo usa imÃ¡genes sin etiquetas
  - Comprime imagen â†’ Reconstruye imagen

Inferencia:
  - Alto error de reconstrucciÃ³n = ANOMALÃA
  - Bajo error de reconstrucciÃ³n = NORMAL
```

**Arquitectura del Autoencoder:**

```
Encoder:          Latent Space:      Decoder:
[128x128x3]  â†’    [Compressed]   â†’   [128x128x3]
    â†“                                     â†‘
  Conv2D                               Conv2DTranspose
    â†“                                     â†‘
  Conv2D         [128 dims]           Conv2DTranspose
    â†“                                     â†‘
  Conv2D                               Conv2DTranspose

Loss = MSE(Original, Reconstruida)
```

---

## ğŸš€ Uso en el Frontend

### Interfaz Actualizada

1. **Seleccionar Tipo de Entrenamiento**:

   - Dropdown con dos opciones
   - Se habilita/deshabilita campo de mÃ¡scaras automÃ¡ticamente

2. **Modo Supervisado**:

   - Campo "ImÃ¡genes": **Requerido** âœ…
   - Campo "MÃ¡scaras": **Requerido** âœ…
   - ParÃ¡metros: patch_size, stride, batch_size, epochs, backbone

3. **Modo No Supervisado**:
   - Campo "ImÃ¡genes": **Requerido** âœ…
   - Campo "MÃ¡scaras": **Deshabilitado** âŒ
   - ParÃ¡metros: batch_size, epochs, latent_dim, validation_split

---

## ğŸ“Š ComparaciÃ³n de Resultados

| CaracterÃ­stica               | Supervisado               | No Supervisado         |
| ---------------------------- | ------------------------- | ---------------------- |
| **PrecisiÃ³n**                | â­â­â­â­â­ Alta           | â­â­â­ Media           |
| **Requiere etiquetas**       | âœ… SÃ­                     | âŒ No                  |
| **Tiempo de preparaciÃ³n**    | ğŸ• Alto (etiquetar)       | âš¡ RÃ¡pido              |
| **Detecta anomalÃ­as nuevas** | âŒ Solo conocidas         | âœ… SÃ­                  |
| **Cantidad de datos**        | Media (100-1000 imÃ¡genes) | Alta (1000+ imÃ¡genes)  |
| **Interpretabilidad**        | â­â­â­â­â­ Muy clara      | â­â­â­ Necesita umbral |

---

## ğŸ› ï¸ Ejemplo de Uso

### Supervisado (con mÃ¡scaras)

```python
# En el frontend
1. Seleccionar "Supervisado (con mÃ¡scaras)"
2. Carpeta imÃ¡genes: data/images/
3. Carpeta mÃ¡scaras: data/masks/
4. Epochs: 25
5. Iniciar entrenamiento

# Resultado
âœ… Modelo entrenado: models/unet_model.keras
âœ… MÃ©tricas: IoU Score, Dice Loss
âœ… Listo para segmentaciÃ³n precisa
```

### No Supervisado (sin mÃ¡scaras)

```python
# En el frontend
1. Seleccionar "No Supervisado (sin mÃ¡scaras - Autoencoder)"
2. Carpeta imÃ¡genes: data/images/  (solo imÃ¡genes normales)
3. Epochs: 50
4. Latent dim: 128
5. Iniciar entrenamiento

# Resultado
âœ… Modelo entrenado: models/autoencoder_model.keras
âœ… Umbral de anomalÃ­a: 0.0234 (calculado automÃ¡ticamente)
âœ… Listo para detecciÃ³n de anomalÃ­as
```

---

## ğŸ“ Estructura de Datos

### Para Supervisado

```
data/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ image_001.tif
â”‚   â”œâ”€â”€ image_002.tif
â”‚   â””â”€â”€ image_003.tif
â””â”€â”€ masks/
    â”œâ”€â”€ image_001.tif  (0=sano, 1=anomalÃ­a)
    â”œâ”€â”€ image_002.tif
    â””â”€â”€ image_003.tif
```

### Para No Supervisado

```
data/
â””â”€â”€ images/
    â”œâ”€â”€ normal_001.tif  (solo imÃ¡genes NORMALES)
    â”œâ”€â”€ normal_002.tif
    â”œâ”€â”€ normal_003.tif
    â””â”€â”€ ...
```

âš ï¸ **Importante para No Supervisado**:

- Entrena **SOLO con imÃ¡genes NORMALES/SANAS**
- El modelo aprenderÃ¡ quÃ© es "normal"
- En inferencia, lo diferente a "normal" = anomalÃ­a

---

## ğŸ“ Referencias

### Supervisado (U-Net)

- Paper: [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597)
- Segmentation Models: https://github.com/qubvel/segmentation_models

### No Supervisado (Autoencoder)

- Paper: [Autoencoding beyond pixels using a learned similarity metric](https://arxiv.org/abs/1512.09300)
- Tutorial: [Anomaly Detection with Autoencoders](https://keras.io/examples/timeseries/timeseries_anomaly_detection/)

---

## ğŸ“ Notas TÃ©cnicas

### Supervisado

```python
# Training
X: imÃ¡genes normalizadas (N, H, W, C)
y: mÃ¡scaras binarias (N, H, W, 1)

# Loss
Loss = DiceLoss(y_true, y_pred)
Metric = IoUScore(y_true, y_pred)
```

### No Supervisado

```python
# Training
X: imÃ¡genes normalizadas (N, H, W, C)
y: mismas imÃ¡genes (N, H, W, C)  # AutoreconstrucciÃ³n

# Loss
Loss = MSE(X, X_reconstructed)

# Inference
reconstruction_error = mean(square(X - X_reconstructed))
is_anomaly = reconstruction_error > threshold
```

---

## ğŸ†˜ FAQ

**P: Â¿Puedo combinar ambos mÃ©todos?**
R: SÃ­! Puedes entrenar primero un Autoencoder (sin mÃ¡scaras) para detectar candidatos, luego etiquetar solo esos candidatos y entrenar U-Net.

**P: Â¿CuÃ¡l es mÃ¡s rÃ¡pido de entrenar?**
R: El Autoencoder suele ser mÃ¡s rÃ¡pido (sin preprocesar mÃ¡scaras), pero requiere mÃ¡s Ã©pocas.

**P: Â¿CuÃ¡l necesita mÃ¡s datos?**
R: No supervisado necesita MÃS datos (solo imÃ¡genes) porque no tiene seÃ±al de etiquetas.

**P: Â¿Puedo usar el Autoencoder si tengo mÃ¡scaras?**
R: SÃ­, pero es mejor usar el mÃ©todo Supervisado para aprovechar las etiquetas.

---

## ğŸ¨ PrÃ³ximas Mejoras

- [ ] Inferencia con Autoencoder (detectar anomalÃ­as en producciÃ³n)
- [ ] VisualizaciÃ³n de error de reconstrucciÃ³n
- [ ] Ensemble: Autoencoder + U-Net
- [ ] Semi-supervisado (pocas mÃ¡scaras + muchas imÃ¡genes)

---

**Â¡Ahora tienes flexibilidad total para entrenar con o sin mÃ¡scaras!** ğŸ‰
